{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code seeks to identify what the best way to optimize a listing on Neighbor.com is. We seek to identify specific features that are correlated with reservation status. The project is organized as follows\n",
    "1. Import Libraries\n",
    "2. Pull in Data\n",
    "3. Clean Data\n",
    "4. Feature Engineering/Deal with Missing Values\n",
    "5. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, mean_squared_error\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pull in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These strings in red need to be replaced with the path of the corresponding files on your computer. These files should be updated periodally by requesting them from preferably Colton Gardner or anyone who can use SQL to pull data from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data Tables\n",
    "\n",
    "# listings.csv\n",
    "listings = pd.read_csv('C:\\\\Users\\\\ben1c\\\\Projects\\\\Neighbor\\\\Listing Optimization\\\\Regression Data\\\\listings.csv')\n",
    "# users.csv\n",
    "users = pd.read_csv('C:\\\\Users\\\\ben1c\\\\Projects\\\\Neighbor\\\\Listing Optimization\\\\Regression Data\\\\users.csv')\n",
    "# reservations.csv\n",
    "reservations = pd.read_csv('C:\\\\Users\\\\ben1c\\\\Projects\\\\Neighbor\\\\Listing Optimization\\\\Regression Data\\\\reservations.csv')\n",
    "# risting_metadata.csv\n",
    "listingmeta = pd.read_csv('C:\\\\Users\\\\ben1c\\\\Projects\\\\Neighbor\\\\Listing Optimization\\\\Regression Data\\\\listing_metadata.csv')\n",
    "# photos.csv\n",
    "photos = pd.read_csv('C:\\\\Users\\\\ben1c\\\\Projects\\\\Neighbor\\\\Listing Optimization\\\\Regression Data\\\\photos.csv')\n",
    "# user_metadata.csv\n",
    "usermeta = pd.read_csv('C:\\\\Users\\\\ben1c\\\\Projects\\\\Neighbor\\\\Listing Optimization\\\\Regression Data\\\\user_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all duplicates, deleted posts or any that aren't published\n",
    "listings.drop_duplicates()\n",
    "listings = listings[listings.status == 'Published']\n",
    "listings = listings[listings['deleted'] != 'True']\n",
    "\n",
    "# Return user data from hosts only\n",
    "users = users[users['is_host']==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell deletes all listings from the last thirty days because they are not representative of the sample we are running this regression on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete listings made in the last 30 days\n",
    "listings = listings[pd.to_datetime(listings['created_at']) <= pd.datetime.now().date()-relativedelta(months=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates new column with Description Length Boolean\n",
    "listings['Description Length'] = np.where(listings['summary'].str.len()>=30, '1', '0')\n",
    "\n",
    "# Creates new column with Title Length Boolean\n",
    "listings['Title Length'] = np.where((listings['listing_name'].str.len()>=10), 1, 0)\n",
    "\n",
    "# Create Storage Type Category\n",
    "listings['Storage Type'] = listings['storage_type'].values\n",
    "\n",
    "# Create Accessibility Category\n",
    "listings['Accessibility'] = listings['access'].values\n",
    "\n",
    "# Create Price Per Square Ft\n",
    "listings['Price Per SQFT'] = (listings['monthly_price'].values)/(listings['width'].values * listings['length'])\n",
    "\n",
    "# Create Day Posted\n",
    "listings['Day Posted'] = pd.to_datetime(listings['created_at']).dt.dayofweek\n",
    "\n",
    "# Create Month Posted\n",
    "listings['Month Posted'] = pd.to_datetime(listings['created_at']).dt.month\n",
    "\n",
    "# Create Reserved Status\n",
    "listings = listings.assign(Reserved=listings.id.isin(reservations.listing_id).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USER METADATA\n",
    "\n",
    "#picking relevant columns\n",
    "dfusermeta = pd.DataFrame(usermeta, columns=['id','user_id','key','value'])\n",
    "df12 = pd.DataFrame(usermeta, columns=['id','user_id','key','value'])\n",
    "\n",
    "#New column with superhost level inputted\n",
    "dfusermeta['Superhost Level'] = dfusermeta[dfusermeta['key']=='superhost_level']['value'].astype(int)\n",
    "df12['Superhost Level'] = np.where(dfusermeta['key']=='superhost_level',dfusermeta['value'],'0')\n",
    "df123 = df12.loc[df12['Superhost Level']!='0']\n",
    "users = pd.merge(users, df123[['user_id', 'Superhost Level']], left_on='id', right_on='user_id', how='left')\n",
    "\n",
    "\n",
    "#Pull in enterprise status\n",
    "dfusermeta['Enterprise'] = dfusermeta[dfusermeta['key']=='enterprise_account']['value']\n",
    "df12['Enterprise'] = np.where(dfusermeta['key']=='enterprise_account', '1', '0')\n",
    "df124 = df12.loc[df12['Enterprise']!='0']\n",
    "users = pd.merge(users, df124[['user_id', 'Enterprise']], left_on='id', right_on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LISTING METADATA\n",
    "df1 = pd.DataFrame(listingmeta, columns= ['id','listing_id','key','value',])\n",
    "df23 = pd.DataFrame(listingmeta, columns= ['id','listing_id','key','value',])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering\n",
    "### Fix Price Score/Manual Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price score ranges from 0 to 1 with .5 being the best score. We manipulated price score such that its range is from -.5 to 0 where a value of 0 represents the best possible score and a value of -.5 means that the assigned price score was .5 away form the ideal price score of .5. Therefore, if you were given a score of .7 (your price is higher than our recommendation) then the value in the column would read in as -.2 because you were .2 away from the ideal price score. We did this to make the coefficient on price score easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull price score data\n",
    "df23['Price Score'] = np.where(df1['key']=='price_score',df1['value'],'0')\n",
    "df234 = df23.loc[df23['Price Score']!='0']\n",
    "df234['Price Score'] = -(abs(df234['Price Score'].astype(float) + -.5))\n",
    "\n",
    "listings = pd.merge(listings, df234[['listing_id', 'Price Score']], left_on='id', right_on='listing_id', how='left')\n",
    "\n",
    "#First Month Discount\n",
    "df23['Discount'] = np.where(df1['key']=='first_month_discount',df1['value'],'0')\n",
    "df234 = df23.loc[df23['Discount']!='0']\n",
    "listings = pd.merge(listings, df234[['listing_id', 'Discount']], left_on='id', right_on='listing_id', how='left')\n",
    "\n",
    "#Pull manual score data\n",
    "df23['Manual Score'] = np.where(df1['key']=='manual_score',df1['value'],'0')\n",
    "df234 = df23.loc[df23['Manual Score']!='0']\n",
    "listings = pd.merge(listings, df234[['listing_id', 'Manual Score']], left_on='id', right_on='listing_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull feature data\n",
    "dffeat = pd.DataFrame(listingmeta, columns= ['id','listing_id','key','value'])\n",
    "dffeat = dffeat[dffeat['key']=='features']\n",
    "dffeat.drop('key', axis = 1, inplace=True)\n",
    "\n",
    "dffeat1 = dffeat['value'].str.split(pat=\",\",expand=True)      \n",
    "dffeat1 = pd.get_dummies(dffeat1.apply(pd.Series).stack()).sum(level=0)\n",
    "dffeat1['id'] = dffeat['listing_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features are listed twice in the original dataframe so we will replace any values of 2 with a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffeat1.replace(2, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.merge(listings, dffeat1, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USERS\n",
    "#picking relevant columns\n",
    "dfusers = pd.DataFrame(users, columns= ['id','bio','is_host','profile_photo_id' , 'lead_source'])\n",
    "\n",
    "#return user data from hosts only\n",
    "dfusers = dfusers[dfusers['is_host']==True]\n",
    "\n",
    "#if they have a bio, counts the number of characters\n",
    "dfusers['bio length'] = np.where(dfusers['bio'].isna(), 0, 1)\n",
    "\n",
    "#Add new column, if they have profile pic then '1' else '0'\n",
    "dfusers['Profile Photo'] = np.where(dfusers['profile_photo_id'].notnull().values,'1','0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PHOTOS\n",
    "\n",
    "#picking relevant columns\n",
    "dfphoto = pd.DataFrame(photos, columns= ['id','imageable_type','imageable_id','filename', 'deleted'])\n",
    "dfphoto2 = pd.DataFrame(photos, columns= ['id','imageable_type','imageable_id','filename', 'deleted'])\n",
    "\n",
    "#returning only undeleted listing photo data\n",
    "dfphoto = dfphoto[dfphoto['imageable_type']=='Listing']\n",
    "\n",
    "#insert new column for streetview and label with 1 and 0 for rows with streetview\n",
    "dfphoto2['streetview'] = np.where((dfphoto2['filename']=='streetView') |(dfphoto2['filename']=='streetview'),'1','0')\n",
    "\n",
    "\n",
    "dfphoto3 = dfphoto2.loc[dfphoto2['streetview']=='1']\n",
    "dfphoto3 = dfphoto3[dfphoto3['deleted']==False]\n",
    "\n",
    "#Add streetview count on listing df\n",
    "listings = pd.merge(listings, dfphoto3[['imageable_id','streetview']], left_on='id', right_on='imageable_id', how='left')\n",
    "\n",
    "\n",
    "#count number of pictures for a listing\n",
    "dfphoto['Frequency'] = dfphoto.groupby('imageable_id')['imageable_id'].transform('count')\n",
    "\n",
    "#drop duplicate rows for the same listing\n",
    "dfphoto.drop_duplicates('imageable_id', inplace=True)\n",
    "dfphoto = dfphoto[dfphoto['deleted']==False]\n",
    "\n",
    "#Add number of pictures on a listing to listing df\n",
    "listings = pd.merge(listings, dfphoto[['imageable_id','Frequency']], left_on='id', right_on='imageable_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the listing and user data together\n",
    "listings = pd.merge(listings,\n",
    "                    users,\n",
    "                    left_on='user_id',\n",
    "                    right_on='id',\n",
    "                    how='left'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.DataFrame()\n",
    "\n",
    "# Bring in Listing Info\n",
    "finaldf['Listing-ID'] = listings['id_x']\n",
    "finaldf['Accessibility'] = listings['Accessibility']\n",
    "finaldf['Storage Type'] = listings['Storage Type']\n",
    "finaldf['Title Length'] = listings['Title Length']\n",
    "finaldf['Description Length'] = listings['Description Length']\n",
    "finaldf['Indoor'] = listings['indoor']\n",
    "finaldf['Day Posted'] = listings['Day Posted']\n",
    "finaldf['Month Posted'] = listings['Month Posted']\n",
    "finaldf['Photos of the Space'] = listings['Frequency']\n",
    "finaldf['Streetview'] = listings['streetview']\n",
    "finaldf['Discount'] = listings['Discount']\n",
    "\n",
    "# Bring in Host Info\n",
    "finaldf['Bio Included'] = dfusers['bio length']\n",
    "finaldf['Profile Photo'] = dfusers['Profile Photo']\n",
    "finaldf['Phone Verified'] = listings['phone_verified']\n",
    "finaldf['Photo ID Verified'] = listings['photo_id_verified']\n",
    "finaldf['Superhost Level'] = listings['Superhost Level']\n",
    "finaldf['Camera'] = listings['camera']\n",
    "finaldf['Climate Controlled'] = listings['climate_controlled']\n",
    "finaldf['Lockable'] = listings['is_lockable']\n",
    "finaldf['No Pets'] = listings['no_pets']\n",
    "finaldf['No Stairs'] = listings['no_stairs']\n",
    "finaldf['Private Entrance'] = listings['private_entrance']\n",
    "finaldf['Smoke Detectors'] = listings['smoke_detectors']\n",
    "finaldf['Smoke Free'] = listings['smoke_free']\n",
    "finaldf['Enterprise'] = listings['Enterprise']\n",
    "\n",
    "# Bring in Review info\n",
    "finaldf['Manual Score'] = listings['Manual Score']\n",
    "finaldf['Price Score'] = listings['Price Score']\n",
    "\n",
    "# Add Reserved Info\n",
    "finaldf['Reserved'] = listings['Reserved']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To remove the entreprise or peer to peer listings simply uncomment the respective lines. To regress on everything just comment out this entire cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress on Enterprise Listings\n",
    "#finaldf = finaldf.loc[finaldf['Enterprise']=='1']\n",
    "\n",
    "# Regress on p2p Listings\n",
    "#finaldf = finaldf.loc[(finaldf['Enterprise']!='1')]\n",
    "\n",
    "#Unused Variables\n",
    "#finaldf['Price Per SQFT'] = listings['Price Per SQFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning missing values\n",
    "#### The following are our reasoning on filling these missing values with zeroes\n",
    "\n",
    "Discount-maybe it didn't exist in the beginning so some of the early ones are are NaN, replace t/f with TRUE/FALSE, then Fill with ZERO  \n",
    "Features - 108 are missing for them all and it appears that they are the same listings, seems like they are outside so it probably means that they just don't have any of those features. FILL WITH ZERO  \n",
    "Price Score- I don't see anything special. DROP ROW  \n",
    "Manual Score- I don't see anything special. DROP ROW  \n",
    "Phone Verified- Fill with zeros  \n",
    "Superhost level - FIll with Zeros  \n",
    "Bio Length- Fill with Zero  \n",
    "Photos of Space- FIll with Zero, because there are no zero values  \n",
    "Streetview- Fill with 0 becuase they don't have it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = finaldf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.replace('true', 1, inplace=True)\n",
    "finaldf.replace('false', 0, inplace=True)\n",
    "finaldf.replace('True', 1, inplace=True)\n",
    "finaldf.replace('False', 0, inplace=True)\n",
    "finaldf.replace('TRUE', 1, inplace=True)\n",
    "finaldf.replace('FALSE', 0, inplace=True)\n",
    "finaldf.replace('f', 0, inplace=True)\n",
    "finaldf.replace('t', 1, inplace=True)\n",
    "finaldf.replace(False, 0, inplace=True)\n",
    "finaldf.replace(True, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = ['Storage Type', 'Accessibility']\n",
    "finaldf = pd.get_dummies(finaldf, columns=dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many types of regressions that you could run here. Essentially in the next two cells you may drop whatever variables you want to pick what you want to regress on reservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ['Listing-ID', 'Indoor', 'Day Posted', 'Month Posted', \n",
    "     'Superhost Level', 'Manual Score', 'Photo ID Verified', 'Enterprise']\n",
    "\n",
    "c = ['Camera', 'Climate Controlled', 'Lockable',\n",
    "       'No Pets', 'No Stairs', 'Private Entrance', 'Smoke Detectors', 'Smoke Free', 'Reserved']\n",
    "\n",
    "control = ['Streetview', 'Discount', 'Price Score', 'Title Length', 'Bio Included', \n",
    "           'Photos of the Space', 'Description Length', 'Profile Photo', 'Reserved']\n",
    "\n",
    "dumstorage = [col for col in finaldf if col.startswith('Storage Type')]  + ['Reserved']\n",
    "dumaccess = [col for col in finaldf if col.startswith('Accessibility')]\n",
    "dum = dumstorage + dumaccess\n",
    "\n",
    "\n",
    "#Regress on the features that a space has\n",
    "def featuresreg(df):\n",
    "    X = pd.DataFrame(df, columns=c)\n",
    "    y = X['Reserved']\n",
    "    X = X.drop(['Reserved'], axis=1)\n",
    "    return X, y\n",
    "\n",
    "#Regress on all the data\n",
    "def alldatareg(df):\n",
    "    X = df\n",
    "    y = X['Reserved']\n",
    "    X = X.drop(['Reserved'], axis=1)\n",
    "    return X , y\n",
    "\n",
    "#Regress on Storage Type\n",
    "def storagetypereg(df):\n",
    "    X = pd.DataFrame(df, columns=dumstorage)\n",
    "    y = X['Reserved']\n",
    "    X = X.drop(['Reserved'], axis=1)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Regress on factors that we can influence\n",
    "def factorswecancontrol(df):\n",
    "    X = pd.DataFrame(df, columns=control)\n",
    "    y = X['Reserved']\n",
    "    X = X.drop(['Reserved'], axis=1)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    446\n",
       "0    282\n",
       "Name: Discount, dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = alldatareg(finaldf)\n",
    "X, y = featuresreg(finaldf)\n",
    "X, y = storagetypereg(finaldf)\n",
    "X, y = factorswecancontrol(finaldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is Y distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0f415a98584e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.distplot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block should only be run if \"y\" is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Resampling for unbalanced data\n",
    "X_resampled, y_resampled = SMOTE(random_state=12).fit_resample(X, y)\n",
    "# # Scale the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(X_resampled), y_resampled, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the reserved rate is balanced then run this block. But don't run both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 0. 0. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-295-1eeaffdab56c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ben1c\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben1c\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben1c\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    647\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m    648\u001b[0m                         \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben1c\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    550\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 0. 0. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(X), y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.775661717236927\n",
      "Test acc: 0.7942332896461337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>-0.337288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u</td>\n",
       "      <td>-0.201193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>-0.100216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o</td>\n",
       "      <td>0.011265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>0.022767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t</td>\n",
       "      <td>0.023752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s</td>\n",
       "      <td>0.057278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i</td>\n",
       "      <td>0.919796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Coefficient\n",
       "0       D    -0.337288\n",
       "1       u    -0.201193\n",
       "2       c    -0.100216\n",
       "3       o     0.011265\n",
       "4       n     0.022767\n",
       "5       t     0.023752\n",
       "6       s     0.057278\n",
       "7       i     0.919796"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegressionCV(penalty='l2', cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "print(\"Train acc: {}\".format(accuracy_score(y_train, train_predictions)))\n",
    "print(\"Test acc: {}\".format(accuracy_score(y_test, test_predictions)))\n",
    "pd.DataFrame(sorted(list(zip(X.columns, clf.coef_[0])), key=lambda x: x[1]), columns={'Feature', 'Coefficient'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-297-9934bed97143>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Feature'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Coefficient'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtext_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Arial'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben1c\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5061\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[0;32m   5062\u001b[0m                 name in self._accessors):\n\u001b[1;32m-> 5063\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5064\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "logresults = pd.DataFrame(sorted(list(zip(X.columns, clf.coef_[0])), key=lambda x: x[1]), columns={'Feature', 'Coefficient'})\n",
    "\n",
    "text_kwargs = dict(fontsize=14, family='Arial')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "ax.bar(logresults['Feature'], logresults['Coefficient'], width=.95, label='Coefficient Value', color='tab:blue')\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_ylabel('Percentage', **text_kwargs)\n",
    "ax.set_xlabel('Variable', **text_kwargs)\n",
    "plt.xticks(rotation=45)\n",
    "ax.legend(loc='upper right')\n",
    "fig.suptitle('Logistic Regression Coefficient', fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.savefig('LRgraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cells below are for running a Random Forest Classifier to predict Reservation Status\n",
    "You will need change the parameters to optimize the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters to change. You will need to change them to maximize your accuracy score\n",
    "n_estimators = [90]\n",
    "max_depth = [15, 12, 11]\n",
    "class_weights = ['balanced', None]\n",
    "best_f1 = 0\n",
    "\n",
    "for est in n_estimators:\n",
    "    for depth in max_depth:\n",
    "        for wgt in class_weights:\n",
    "            print(est, depth, wgt)\n",
    "            clf = RandomForestClassifier(n_estimators=est, max_depth=depth, oob_score=True, class_weight=wgt)\n",
    "            clf.fit(X_train, y_train)\n",
    "            f1 = f1_score(y_train, np.argmax(clf.oob_decision_function_ , 1))\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = (est, depth, wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best OOB F1: {}\".format(best_f1))\n",
    "print(\"Best params: {}\".format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=best_params[0], max_depth=best_params[1], class_weight=best_params[2])\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "test_predictions = rfc.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = sorted(list(zip(X.columns, rfc.feature_importances_)), key=lambda x: x[1], reverse=True)\n",
    "pd.Series([x[1] for x in feature_imp[:]], index=[x[0] for x in feature_imp[:]]).plot(kind='bar', figsize=(14, 4))\n",
    "fig.suptitle('Random Forest Feature Importances', fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.savefig('RFCgraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cell below will write outputs to a separate document\n",
    "These include:  \n",
    "Final dataframe that is being regressed  \n",
    "Accuracy scores for each regression  \n",
    "Graphs for each regression  \n",
    "  \n",
    "You will need to change the file path to tell it where to write the files. Pick any file name you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('C:\\\\Users\\\\ben1c\\\\Projects\\\\Neighbor\\\\Listing Optimization\\\\Regression Data\\\\finaldfEnterprise.csv', 'a') as f:\n",
    "#     finaldf.to_csv(f, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
